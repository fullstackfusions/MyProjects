{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the time complexity of recursive functions involves understanding how the number of function calls grows with the size of the input. Let's explore two classic examples: the Fibonacci sequence and binary search implemented recursively. These examples will help illustrate how to analyze the time complexity of recursive algorithms.\n",
    "\n",
    "### 1. Fibonacci Sequence (Naive Recursive Implementation)\n",
    "\n",
    "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. The naive recursive implementation is a direct translation of this definition into code.\n",
    "\n",
    "```python\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "# Time Complexity: O(2^n)\n",
    "```\n",
    "\n",
    "**Analysis**:\n",
    "- At each step, the function splits into two recursive calls, creating a binary tree of calls.\n",
    "- The depth of this call tree is `n`, and at each level, the number of calls doubles.\n",
    "- Thus, the total number of calls is roughly `2^0 + 2^1 + 2^2 + ... + 2^(n-1)`, which is **O(2^n)**.\n",
    "- This exponential growth makes the naive recursive Fibonacci very inefficient for large `n`.\n",
    "\n",
    "### 2. Binary Search (Recursive Implementation)\n",
    "\n",
    "Binary search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion of the list that could contain the item, until the possible locations are narrowed down to just one.\n",
    "\n",
    "```python\n",
    "def binary_search(arr, low, high, target):\n",
    "    if high >= low:\n",
    "        mid = (high + low) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] > target:\n",
    "            return binary_search(arr, low, mid - 1, target)\n",
    "        else:\n",
    "            return binary_search(arr, mid + 1, high, target)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Time Complexity: O(log n)\n",
    "```\n",
    "\n",
    "**Analysis**:\n",
    "- At each recursive call, the search space is halved.\n",
    "- This halving continues until the element is found or the search space is empty.\n",
    "- The number of times you can halve `n` until you get to 1 is **log(n)**, hence the time complexity is **O(log n)**.\n",
    "- This shows a logarithmic growth rate, making binary search much more efficient than the naive Fibonacci implementation.\n",
    "\n",
    "### 3. Tower of Hanoi\n",
    "\n",
    "The Tower of Hanoi is a classic problem that involves moving a stack of disks from one rod to another, with the constraint that only one disk can be moved at a time and a larger disk cannot be placed on top of a smaller disk. The solution involves recursion.\n",
    "\n",
    "```python\n",
    "def tower_of_hanoi(n, source, auxiliary, target):\n",
    "    if n == 1:\n",
    "        print(f\"Move disk 1 from {source} to {target}\")\n",
    "        return\n",
    "    tower_of_hanoi(n-1, source, target, auxiliary)\n",
    "    print(f\"Move disk {n} from {source} to {target}\")\n",
    "    tower_of_hanoi(n-1, auxiliary, source, target)\n",
    "\n",
    "# Time Complexity: O(2^n)\n",
    "```\n",
    "\n",
    "**Analysis**:\n",
    "- For `n` disks, the first step is to move `n-1` disks to the auxiliary rod, then move the `nth` disk to the target, and finally move the `n-1` disks from the auxiliary to the target.\n",
    "- This creates two recursive calls for `n-1` disks plus one move operation, leading to the recurrence relation T(n) = 2T(n-1) + 1.\n",
    "- Solving this recurrence relation gives a time complexity of **O(2^n)**.\n",
    "\n",
    "### 4. Recursive Tree Traversal (Pre-order)\n",
    "\n",
    "Tree traversal algorithms visit every node in a tree data structure. Pre-order traversal visits the root, then recursively visits the left and right subtrees.\n",
    "\n",
    "```python\n",
    "class TreeNode:\n",
    "    def __init__(self, value=0, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "def preorder_traversal(root):\n",
    "    if root:\n",
    "        print(root.value)  # Visit the root\n",
    "        preorder_traversal(root.left)  # Recursively traverse left subtree\n",
    "        preorder_traversal(root.right)  # Recursively traverse right subtree\n",
    "\n",
    "# Time Complexity: O(n)\n",
    "```\n",
    "\n",
    "**Analysis**:\n",
    "- Each node in the tree is visited exactly once.\n",
    "- If the tree has `n` nodes, the time complexity is **O(n)**, as the function makes a single visit to each node.\n",
    "\n",
    "### 5. Sum of an Array Using Recursion\n",
    "\n",
    "Calculating the sum of an array using recursion involves breaking down the problem into smaller subarrays and combining their sums.\n",
    "\n",
    "```python\n",
    "def recursive_sum(arr):\n",
    "    if len(arr) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return arr[0] + recursive_sum(arr[1:])\n",
    "\n",
    "# Time Complexity: O(n)\n",
    "```\n",
    "\n",
    "**Analysis**:\n",
    "- Each call processes one element of the array (the head) and makes a recursive call to process the rest (the tail).\n",
    "- This results in `n` recursive calls for an array of size `n`, leading to a linear time complexity, **O(n)**.\n",
    "- Note: This implementation also incurs additional time and space costs due to slicing the array. In practice, passing indices to indicate the current portion of the array to be summed could be more efficient.\n",
    "\n",
    "### Recursion Analysis Key Points\n",
    "\n",
    "- **Tree Representation**: Often, visualizing the recursive calls as a tree can help understand how the function grows with input size. The structure of this tree and the number of nodes at each level provide insights into the time complexity.\n",
    "- **Recurrence Relations**: For more complex recursive algorithms, writing down the recurrence relation and solving it (using methods like the Master Theorem or recursion tree method) is necessary to determine the time complexity.\n",
    "- **Base Cases and Recursive Calls**: Analyzing how quickly the algorithm approaches its base cases can also provide clues about its efficiency.\n",
    "\n",
    "Understanding the time complexity of recursive functions is crucial for evaluating their performance and for choosing or optimizing algorithms in software development and algorithmic problem solving."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
